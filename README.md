# AI Research Hub ğŸ¤–ğŸ“š

Ein intelligentes Forschungs-Tool, das automatisch KI-relevante Artikel aus verschiedenen Quellen sammelt, zusammenfasst und analysiert. Mit integriertem AI-Chat-Assistenten fÃ¼r erweiterte Recherche und Analyse.

## ğŸŒŸ Features

### ğŸ“Š Dashboard
- **Echtzeit-Ãœbersicht** Ã¼ber aktuelle KI-Forschung und News
- **Interaktive Diagramme** fÃ¼r Trends und Quellen-Statistiken
- **Top-Keywords** und Trending-Topics-Analyse
- **Responsive Design** mit Dark/Light Mode

### ğŸ” Multi-Source Datensammlung
- **ArXiv**: Aktuelle KI-Forschungsarbeiten mit Zitationsstilen
- **TechCrunch**: KI-relevante Tech-News
- **VentureBeat**: Startup- und Business-KI-News
- **Stanford AI Blog**: Akademische KI-Insights
- **The Verge**: Tech-Journalismus zu KI-Themen
- **The Hacker News**: Cybersecurity mit KI-Fokus

### ğŸ¤– AI-Chat-Assistent
- **OpenAI-Integration** fÃ¼r intelligente Artikel-Analyse
- **Kontextuelle Antworten** basierend auf gesammelten Artikeln
- **Mehrsprachige UnterstÃ¼tzung** (DE/EN/FR/ZH)
- **Persistente Chat-Historie**

### âš™ï¸ Erweiterte Funktionen
- **Automatische Relevanz-Bewertung** mit KI-Keywords
- **Flexible Export-Optionen** (Word, JSON, Text)
- **Caching-System** fÃ¼r Performance-Optimierung
- **Benutzerfreundliche Einstellungen**

## ğŸš€ Installation

### Voraussetzungen
- Python 3.8+
- Google Chrome (fÃ¼r Web-Scraping)
- OpenAI API Key

### 1. Repository klonen
```bash
git clone https://github.com/yourusername/ai-research-hub.git
cd ai-research-hub
```

### 2. Virtual Environment erstellen
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate  # Windows
```

### 3. Dependencies installieren
```bash
pip install -r requirements.txt
```

### 4. Umgebungsvariablen konfigurieren
Erstellen Sie eine `.env`-Datei im Projektverzeichnis:
```env
# OpenAI API Key (erforderlich)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Weitere Einstellungen
FLASK_SECRET_KEY=your_secret_key_here
OPENAI_MODEL=gpt-3.5-turbo
THEME=light
DEFAULT_SOURCES=arxiv,techcrunch,venturebeat
MAX_RESULTS=10
DB_PATH=research_data.db
```

### 5. Anwendung starten
```bash
python app.py
```

Die Anwendung ist dann unter `http://localhost:5000` verfÃ¼gbar.

## ğŸ“± Verwendung

### 1. Quellen konfigurieren
- Navigieren Sie zur **Sources**-Seite
- WÃ¤hlen Sie gewÃ¼nschte Datenquellen aus
- Konfigurieren Sie Parameter (max. Artikel, ArXiv-Kategorien, etc.)
- Klicken Sie auf "Daten abrufen"

### 2. Dashboard analysieren
- **Aktuelle Artikel** durchstÃ¶bern
- **Trend-Diagramme** analysieren
- **Top-Keywords** verfolgen
- **Quellen-Statistiken** einsehen

### 3. AI-Chat nutzen
- Stellen Sie Fragen zu gesammelten Artikeln
- Lassen Sie sich Trends erklÃ¤ren
- Vergleichen Sie verschiedene ForschungsansÃ¤tze
- Exportieren Sie Chat-VerlÃ¤ufe

### 4. Berichte exportieren
- Word-Dokumente mit Zusammenfassungen
- JSON-Daten fÃ¼r weitere Analyse
- Verschiedene Zitationsstile (APA, MLA, Chicago, BibTeX)

## ğŸ› ï¸ Technische Details

### Architektur
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Data Layer    â”‚
â”‚   (HTML/JS)     â”‚â—„â”€â”€â–ºâ”‚   (Flask)       â”‚â—„â”€â”€â–ºâ”‚   (SQLite)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   AI Services   â”‚
                       â”‚   (OpenAI)      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Hauptkomponenten
- **app.py**: Haupt-Flask-Anwendung
- **scrapers/**: Datensammlung von verschiedenen Quellen
- **templates/**: Frontend-Templates
- **static/**: CSS, JavaScript, Assets
- **db_manager.py**: Datenbankoperationen
- **relevance.py**: KI-Relevanz-Analyse

### Datenbank Schema
```sql
-- Artikel-Tabelle
CREATE TABLE articles (
    id INTEGER PRIMARY KEY,
    title TEXT NOT NULL,
    source TEXT NOT NULL,
    url TEXT,
    summary TEXT,
    content TEXT,
    pub_date TEXT,
    keywords TEXT,
    relevance_score REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ“¦ Projektstruktur

```
ai-research-hub/
â”œâ”€â”€ app.py                 # Haupt-Flask-Anwendung
â”œâ”€â”€ web_app.py            # Alternative Flask-App
â”œâ”€â”€ requirements.txt      # Python-Dependencies
â”œâ”€â”€ .env                  # Umgebungsvariablen
â”œâ”€â”€ .gitignore           # Git-Ignore-Datei
â”œâ”€â”€ README.md            # Diese Datei
â”œâ”€â”€ LICENSE              # MIT-Lizenz
â”‚
â”œâ”€â”€ scrapers/            # Datensammlung
â”‚   â”œâ”€â”€ arxiv_scraper.py
â”‚   â”œâ”€â”€ techcrunch.py
â”‚   â”œâ”€â”€ venture_beat.py
â”‚   â”œâ”€â”€ stanford_ai.py
â”‚   â”œâ”€â”€ theverge.py
â”‚   â””â”€â”€ thn.py
â”‚
â”œâ”€â”€ templates/           # HTML-Templates
â”‚   â”œâ”€â”€ layout.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ sources.html
â”‚   â”œâ”€â”€ chat.html
â”‚   â””â”€â”€ settings.html
â”‚
â”œâ”€â”€ static/              # Frontend-Assets
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ cache/               # Zwischenspeicher
â”œâ”€â”€ summary/             # Export-Dateien
â””â”€â”€ logs/                # Log-Dateien
```

## ğŸ”§ Konfiguration

### Scraper-Einstellungen
```python
# Maximale Artikel pro Quelle
MAX_ARTICLES = 10

# ArXiv-Kategorien
ARXIV_CATEGORIES = ['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV']

# Cache-Verhalten
CACHE_DURATION = 3600  # 1 Stunde
```

### OpenAI-Einstellungen
```python
# Verwendetes Modell
OPENAI_MODEL = 'gpt-3.5-turbo'

# Max. Tokens pro Anfrage
MAX_TOKENS = 500

# Temperatur (KreativitÃ¤t)
TEMPERATURE = 0.7
```

## ğŸ› Troubleshooting

### HÃ¤ufige Probleme

#### 1. OpenAI API-Fehler
```
Error: OpenAI API key not set
```
**LÃ¶sung**: Setzen Sie `OPENAI_API_KEY` in der `.env`-Datei

#### 2. Chrome-Driver-Fehler
```
Error: ChromeDriver not found
```
**LÃ¶sung**: Installieren Sie Chrome und aktualisieren Sie den WebDriver:
```bash
pip install --upgrade webdriver-manager
```

#### 3. Keine Daten vom Dashboard
```
Error: No sources selected
```
**LÃ¶sung**: 
- Gehen Sie zur Sources-Seite
- WÃ¤hlen Sie mindestens eine Quelle aus
- Klicken Sie auf "Daten abrufen"

#### 4. Langsame Performance
**LÃ¶sung**: 
- Reduzieren Sie `MAX_ARTICLES` in den Einstellungen
- Leeren Sie den Cache-Ordner
- PrÃ¼fen Sie Ihre Internetverbindung

## ğŸ“ˆ Performance-Optimierung

### Caching-Strategien
- **Artikel-Cache**: 1 Stunde fÃ¼r bereits verarbeitete Artikel
- **Database-Cache**: Lokale SQLite-Datenbank fÃ¼r schnelle Abfragen
- **API-Cache**: Rate-Limiting fÃ¼r externe APIs

### Monitoring
```python
# Logging-Konfiguration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('app.log')
    ]
)
```

## ğŸ¤ Contributing

BeitrÃ¤ge sind willkommen! Bitte beachten Sie:

1. **Fork** das Repository
2. **Erstellen** Sie einen Feature-Branch (`git checkout -b feature/amazing-feature`)
3. **Committen** Sie Ihre Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. **Push** zum Branch (`git push origin feature/amazing-feature`)
5. **Erstellen** Sie eine Pull Request

### Entwicklungsrichtlinien
- Verwenden Sie aussagekrÃ¤ftige Commit-Messages
- FÃ¼gen Sie Tests fÃ¼r neue Features hinzu
- Dokumentieren Sie Ihre Ã„nderungen
- Befolgen Sie PEP 8 fÃ¼r Python-Code

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) fÃ¼r Details.


*Dieses Tool wurde entwickelt, um Forschern und KI-Enthusiasten zu helfen, mit den neuesten Entwicklungen in der KÃ¼nstlichen Intelligenz Schritt zu halten.*